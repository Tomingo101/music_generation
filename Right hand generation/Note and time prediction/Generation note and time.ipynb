{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Note and time final.ipynb","provenance":[],"collapsed_sections":["gZJznJRC8srI","6z1kmYWHNsK4","L6v_HGOd8y1N","5zNjY6fkN_wP","W3yH8Gsu_kA7","Y-kI3TzTnA9Z","xJTtHacQdHU3"],"toc_visible":true,"authorship_tag":"ABX9TyNGNFTecnYgmKd8EeJjAUq4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gZJznJRC8srI"},"source":["# **Import libraries**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-45eEvdJ8nOr","executionInfo":{"status":"ok","timestamp":1614548616313,"user_tz":-60,"elapsed":2740,"user":{"displayName":"tom vesoul","photoUrl":"","userId":"10135283741654588830"}},"outputId":"274de632-2d60-4bc0-df9e-c1367737042c"},"source":["!pip install mido"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: mido in /usr/local/lib/python3.7/dist-packages (1.2.9)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cTbDl8PI8fYg","executionInfo":{"status":"ok","timestamp":1614548616314,"user_tz":-60,"elapsed":2532,"user":{"displayName":"tom vesoul","photoUrl":"","userId":"10135283741654588830"}}},"source":["import mido # easy to use python MIDI library\n","import matplotlib.pyplot as plt # plotting\n","import numpy as np # linear algebra\n","import os # accessing directory structure\n","import random\n","import pandas as pd\n","\n","from mido import MidiFile, MidiTrack, Message\n","\n","from sklearn import model_selection\n","\n","import torch \n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C_IWJPBcOPBF","executionInfo":{"status":"ok","timestamp":1614548616314,"user_tz":-60,"elapsed":2396,"user":{"displayName":"tom vesoul","photoUrl":"","userId":"10135283741654588830"}},"outputId":"485b8295-0d20-43d0-953e-fe0425ffc776"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"6z1kmYWHNsK4"},"source":["# **Hyperparameters**"]},{"cell_type":"code","metadata":{"id":"H39jJFdVNvUu","executionInfo":{"status":"ok","timestamp":1614548786801,"user_tz":-60,"elapsed":600,"user":{"displayName":"tom vesoul","photoUrl":"","userId":"10135283741654588830"}}},"source":["num_epochs = 100\n","batch_size = 1024\n","\n","sequence_length = 16\n","embedding_dim_note = 128\n","embedding_dim_time = 128\n","\n","hidden_size = 512\n","num_layers = 1\n","num_classes_note = 128\n","num_classes_time = 18\n","\n","learning_rate = 0.05"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L6v_HGOd8y1N"},"source":["# **Load data**"]},{"cell_type":"code","metadata":{"id":"xj0LRySn8jq3","executionInfo":{"status":"ok","timestamp":1614548617070,"user_tz":-60,"elapsed":1939,"user":{"displayName":"tom vesoul","photoUrl":"","userId":"10135283741654588830"}}},"source":["df_train = pd.read_csv('train_note_time.csv', header=None)\n","df_val = pd.read_csv('val_note_time.csv', header=None)\n","\n","array_train = df_train.values\n","array_val = df_val.values"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"BLWHch9k_gI2","executionInfo":{"status":"ok","timestamp":1614548617071,"user_tz":-60,"elapsed":986,"user":{"displayName":"tom vesoul","photoUrl":"","userId":"10135283741654588830"}}},"source":["train_loader = torch.utils.data.DataLoader(dataset=array_train,\n","                                           batch_size=batch_size, \n","                                           shuffle=True)\n","\n","val_loader = torch.utils.data.DataLoader(dataset=array_val,\n","                                           batch_size=batch_size, \n","                                           shuffle=True)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5zNjY6fkN_wP"},"source":["# **Models**"]},{"cell_type":"code","metadata":{"id":"2vgA2zmzmO9k","executionInfo":{"status":"ok","timestamp":1614548729584,"user_tz":-60,"elapsed":763,"user":{"displayName":"tom vesoul","photoUrl":"","userId":"10135283741654588830"}}},"source":["# RNN architecture\n","class RNN(nn.Module):\n","  def __init__(self, num_classes_note, num_classes_time, embedding_dim_note, embedding_dim_time, hidden_size, num_layers, drop_prob=0., drop_fc=0.):\n","    super(RNN, self).__init__()\n","\n","    self.embedding_note = nn.Embedding(num_classes_note, embedding_dim_note)\n","    self.embedding_time = nn.Embedding(num_classes_time, embedding_dim_time)\n","\n","    self.hidden_size = hidden_size\n","    self.num_layers = num_layers\n","    self.lstm = nn.RNN(embedding_dim_note + embedding_dim_time, hidden_size, num_layers, dropout=drop_prob, batch_first=True)\n","\n","    self.fc_note_1 = nn.Linear(hidden_size, hidden_size)\n","    self.fc_note_2 = nn.Linear(hidden_size, num_classes_note)\n","\n","    self.fc_time_1 = nn.Linear(hidden_size, hidden_size)\n","    self.fc_time_2 = nn.Linear(hidden_size, num_classes_time)\n","\n","    self.relu = nn.ReLU()\n","    self.dropout = nn.Dropout(p=drop_fc)\n","    \n","  def forward(self, inputs):\n","    notes, time = inputs\n","    # Embedding layers\n","    embeddings_note = self.embedding_note(notes) # Output shape (batch, sequence_length, embedding_dim)\n","    embeddings_time = self.embedding_time(time)\n","    x = torch.cat((embeddings_note, embeddings_time), dim=2)\n","\n","    # Set initial hidden and cell states \n","    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n","    \n","    # Forward propagate LSTM\n","    out, hidden = self.lstm(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n","    out = out[:, -1, :] # Hidden state of the last element of the sequence \n","    \n","    #FC\n","    note = self.fc_note_1(out)\n","    note = self.relu(note)\n","    note = self.fc_note_2(note)\n","\n","    time = self.fc_time_1(out)\n","    time = self.dropout(time)\n","    time = self.relu(time)\n","    time = self.fc_time_2(time)\n","\n","    return note, time"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"X5A4BPr8mRbK","executionInfo":{"status":"ok","timestamp":1614548729585,"user_tz":-60,"elapsed":539,"user":{"displayName":"tom vesoul","photoUrl":"","userId":"10135283741654588830"}}},"source":["# GRU architecture\n","class GRU(nn.Module):\n","  def __init__(self, num_classes_note, num_classes_time, embedding_dim_note, embedding_dim_time, hidden_size, num_layers, drop_prob=0., drop_fc=0.):\n","    super(GRU, self).__init__()\n","\n","    self.embedding_note = nn.Embedding(num_classes_note, embedding_dim_note)\n","    self.embedding_time = nn.Embedding(num_classes_time, embedding_dim_time)\n","\n","    self.hidden_size = hidden_size\n","    self.num_layers = num_layers\n","    self.lstm = nn.GRU(embedding_dim_note + embedding_dim_time, hidden_size, num_layers, dropout=drop_prob, batch_first=True)\n","\n","    self.fc_note_1 = nn.Linear(hidden_size, hidden_size)\n","    self.fc_note_2 = nn.Linear(hidden_size, num_classes_note)\n","\n","    self.fc_time_1 = nn.Linear(hidden_size, hidden_size)\n","    self.fc_time_2 = nn.Linear(hidden_size, num_classes_time)\n","\n","    self.relu = nn.ReLU()\n","    self.dropout = nn.Dropout(p=drop_fc)\n","    \n","  def forward(self, inputs):\n","    notes, time = inputs\n","    # Embedding layers\n","    embeddings_note = self.embedding_note(notes) # Output shape (batch, sequence_length, embedding_dim)\n","    embeddings_time = self.embedding_time(time)\n","    x = torch.cat((embeddings_note, embeddings_time), dim=2)\n","\n","    # Set initial hidden and cell states \n","    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n","    \n","    # Forward propagate LSTM\n","    out, hidden = self.lstm(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n","    out = out[:, -1, :] # Hidden state of the last element of the sequence \n","    \n","    #FC\n","    note = self.fc_note_1(out)\n","    note = self.relu(note)\n","    note = self.fc_note_2(note)\n","\n","    time = self.fc_time_1(out)\n","    time = self.dropout(time)\n","    time = self.relu(time)\n","    time = self.fc_time_2(time)\n","\n","    return note, time"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"iIiAEO88PNcD","executionInfo":{"status":"ok","timestamp":1614548729915,"user_tz":-60,"elapsed":571,"user":{"displayName":"tom vesoul","photoUrl":"","userId":"10135283741654588830"}}},"source":["# LSTM architecture\n","class LSTM(nn.Module):\n","  def __init__(self, num_classes_note, num_classes_time, embedding_dim_note, embedding_dim_time, hidden_size, num_layers, drop_prob=0., drop_fc=0.):\n","    super(LSTM, self).__init__()\n","\n","    self.embedding_note = nn.Embedding(num_classes_note, embedding_dim_note)\n","    self.embedding_time = nn.Embedding(num_classes_time, embedding_dim_time)\n","\n","    self.hidden_size = hidden_size\n","    self.num_layers = num_layers\n","    self.lstm = nn.LSTM(embedding_dim_note + embedding_dim_time, hidden_size, num_layers, dropout=drop_prob, batch_first=True)\n","\n","    self.fc_note_1 = nn.Linear(hidden_size, hidden_size)\n","    self.fc_note_2 = nn.Linear(hidden_size, num_classes_note)\n","\n","    self.fc_time_1 = nn.Linear(hidden_size, hidden_size)\n","    self.fc_time_2 = nn.Linear(hidden_size, num_classes_time)\n","\n","    self.relu = nn.ReLU()\n","    self.dropout = nn.Dropout(p=drop_fc)\n","    \n","  def forward(self, inputs):\n","    notes, time = inputs\n","    # Embedding layers\n","    embeddings_note = self.embedding_note(notes) # Output shape (batch, sequence_length, embedding_dim)\n","    embeddings_time = self.embedding_time(time)\n","    x = torch.cat((embeddings_note, embeddings_time), dim=2)\n","\n","    # Set initial hidden and cell states \n","    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n","    c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n","    \n","    # Forward propagate LSTM\n","    out, hidden = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n","    out = out[:, -1, :] # Hidden state of the last element of the sequence \n","    \n","    #FC\n","    note = self.fc_note_1(out)\n","    note = self.relu(note)\n","    note = self.fc_note_2(note)\n","\n","    time = self.fc_time_1(out)\n","    time = self.dropout(time)\n","    time = self.relu(time)\n","    time = self.fc_time_2(time)\n","\n","    return note, time"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W3yH8Gsu_kA7"},"source":["# **Training**"]},{"cell_type":"markdown","metadata":{"id":"HcOcQvB3fE-f"},"source":["## Accuracy "]},{"cell_type":"code","metadata":{"id":"nBIn4DTjfOnw","executionInfo":{"status":"ok","timestamp":1614548790029,"user_tz":-60,"elapsed":743,"user":{"displayName":"tom vesoul","photoUrl":"","userId":"10135283741654588830"}}},"source":["def validate_model(model, loader):\n","    model.eval()\n","    with torch.no_grad():\n","        correct_note = 0\n","        correct_time = 0\n","        total = 0\n","        for batch in loader:\n","            batch = torch.reshape(batch, (batch.shape[0], -1 , 3))\n","            notes = batch[:,:,0]\n","            velocity = batch[:,:,1]\n","            time = batch[:,:,2]\n","\n","            notes_sequence = notes[:,:16].to(device)\n","            notes_target = notes[:,16].to(device)\n","\n","            time = (time * 2) // 60 - (time // 60)\n","            time = torch.min(time, torch.tensor([17]))\n","            time_sequence = time[:,:16].to(device)\n","            time_target = time[:,16].to(device)\n","\n","            inputs = (notes_sequence, time_sequence)\n","\n","            note, time = model(inputs)\n","\n","            # Accuracy note\n","            _, predicted = torch.max(note.data, 1)\n","            correct_note += (predicted == notes_target).sum().item()\n","            total += notes_target.size(0)\n","\n","            # Accuracy time\n","            _, predicted = torch.max(time.data, 1)\n","            correct_time += (predicted == time_target).sum().item()\n","\n","        accuracy_note = 100 * correct_note / total\n","        accuracy_time = 100 * correct_time / total\n","\n","    return accuracy_note, accuracy_time"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0H3umlWRfPNJ"},"source":["## Training loop"]},{"cell_type":"code","metadata":{"id":"ArkqUsBtmsQT","executionInfo":{"status":"ok","timestamp":1614548790901,"user_tz":-60,"elapsed":470,"user":{"displayName":"tom vesoul","photoUrl":"","userId":"10135283741654588830"}}},"source":["def train_model(model, optimizer, train_loader, val_loader, num_epochs, lr_scheduler=None, display_loss=False):\n","  criterion_note = nn.CrossEntropyLoss()\n","  criterion_time = nn.CrossEntropyLoss()\n","\n","  best_val_accuracy_note = 0\n","  best_val_accuracy_time = 0\n","  best_epoch_note = 0\n","  best_epcoh_time = 0\n","\n","  for epoch in range(num_epochs):\n","\n","    model.train()\n","\n","    #### UPDATE LEARNING RATE #### \n","    if lr_scheduler == 'multi_steps':\n","        if epoch in [int(num_epochs * 0.5)]:\n","            for param_group in optimizer.param_groups:\n","                param_group['lr'] *= 0.1\n","\n","    for i, batch in enumerate(train_loader):\n","      batch = torch.reshape(batch, (batch.shape[0], -1 , 3))\n","      notes = batch[:,:,0]\n","      velocity = batch[:,:,1]\n","      time = batch[:,:,2]\n","\n","      notes_sequence = notes[:,:16].to(device)\n","      notes_target = notes[:,16].to(device)\n","\n","      time = (time * 2) // 60 - (time // 60)\n","      time = torch.min(time, torch.tensor([17]))\n","      time_sequence = time[:,:16].to(device)\n","      time_target = time[:,16].to(device)\n","\n","      inputs = (notes_sequence, time_sequence)\n","\n","      optimizer.zero_grad()\n","      note, time = model(inputs)\n","\n","      loss_note = torch.mean(criterion_note(note, notes_target))\n","      loss_time = torch.mean(criterion_time(time, time_target))\n","      loss = loss_note + loss_time\n","\n","      loss.backward()\n","      optimizer.step()\n","\n","      if i % 300 == 0 and display_loss:\n","        print(f'Epoch : {epoch}, Step: {i}, Loss: {round(loss.item(), 2)}')\n","\n","    # Train accuracy \n","    train_accuracy_note, train_accuracy_time = validate_model(model, train_loader)\n","    train_accuracy_note = round(train_accuracy_note, 2)\n","    train_accuracy_time = round(train_accuracy_time, 2)\n","\n","    # Val accuracy\n","    val_accuracy_note, val_accuracy_time = validate_model(model, val_loader)\n","    val_accuracy_note = round(val_accuracy_note, 2)\n","    val_accuracy_time = round(val_accuracy_time, 2)\n","\n","\n","    if val_accuracy_note > best_val_accuracy_note:\n","      best_val_accuracy_note = val_accuracy_note\n","      best_epoch_note = epoch\n","\n","    if val_accuracy_time > best_val_accuracy_time:\n","      best_val_accuracy_time = val_accuracy_time\n","      best_epoch_time = epoch\n","\n","    print('################')\n","    print(f'Epoch: {epoch}, Loss note: {round(loss_note.item(), 2)}, Loss time: {round(loss_time.item(), 2)}')\n","    print(f'Epoch : {epoch}, Train accuracy note : {train_accuracy_note} %, Val accuracy note : {val_accuracy_note} %')\n","    print(f'Best val accuracy at epoch {best_epoch_note}: {best_val_accuracy_note} %')\n","    print('------')\n","    print(f'Epoch : {epoch}, Train accuracy time : {train_accuracy_time} %, Val accuracy time : {val_accuracy_time} %')\n","    print(f'Best val accuracy at epoch {best_epoch_time}: {best_val_accuracy_time} %')"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y-kI3TzTnA9Z"},"source":["# **Experiments**"]},{"cell_type":"code","metadata":{"id":"ZKxcCV7iPAIr","executionInfo":{"status":"error","timestamp":1614548819754,"user_tz":-60,"elapsed":2,"user":{"displayName":"tom vesoul","photoUrl":"","userId":"10135283741654588830"}}},"source":["# Best result\n","model = RNN(num_classes_note, num_classes_time, embedding_dim_note=128, embedding_dim_time=128, hidden_size=512, num_layers=3).to(device)\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.05, nesterov=True, momentum=0.9)\n","\n","train_model(model, optimizer, train_loader, val_loader, num_epochs=100, lr_scheduler='multi_steps')"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"IHvPJm8Cm9YW"},"source":["# Best result\n","model = GRU(num_classes_note, num_classes_time, embedding_dim_note=128, embedding_dim_time=128, hidden_size=512, num_layers=3).to(device)\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.05, nesterov=True, momentum=0.9)\n","\n","train_model(model, optimizer, train_loader, val_loader, num_epochs=100, lr_scheduler='multi_steps')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IBjzd4ienAg0"},"source":["# Best result\n","model = LSTM(num_classes_note, num_classes_time, embedding_dim_note=128, embedding_dim_time=128, hidden_size=512, num_layers=3).to(device)\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.05, nesterov=True, momentum=0.9)\n","\n","train_model(model, optimizer, train_loader, val_loader, num_epochs=100, lr_scheduler='multi_steps')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xJTtHacQdHU3"},"source":["# **Music generation**"]},{"cell_type":"markdown","metadata":{"id":"tPe8tBGFd_WX"},"source":["## Mido utils"]},{"cell_type":"code","metadata":{"id":"li_vB3yOdm6p","executionInfo":{"status":"ok","timestamp":1614548919209,"user_tz":-60,"elapsed":721,"user":{"displayName":"tom vesoul","photoUrl":"","userId":"10135283741654588830"}}},"source":["def data_to_track(data):\n","    track = MidiTrack()\n","    for values in data:\n","        note = values[0]\n","        velocity = values[1]\n","        time = values[2]\n","        track.append(Message('note_on', channel=0, note=note, velocity=velocity, time=time))\n","    return(track)\n","    "],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"dUh7p2jveSfs","executionInfo":{"status":"ok","timestamp":1614548919573,"user_tz":-60,"elapsed":947,"user":{"displayName":"tom vesoul","photoUrl":"","userId":"10135283741654588830"}}},"source":["def save_track(track, path):\n","    mid = MidiFile()\n","    mid.tracks.append(track)\n","    mid.save(path)"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y60p3SOlm72x"},"source":["## Generation"]},{"cell_type":"code","metadata":{"id":"yKhQ8AMc4gmR","executionInfo":{"status":"ok","timestamp":1614548942084,"user_tz":-60,"elapsed":605,"user":{"displayName":"tom vesoul","photoUrl":"","userId":"10135283741654588830"}}},"source":["# Random generation\n","n_predictions = 1000\n","temp_note = 1.5\n","temp_time = 1.5\n","initial_note = 60\n","\n","list_notes = [initial_note]\n","list_times = [0]\n","velocity = 50\n","data = [[initial_note, velocity, 0]]"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"vsQgU-BdbIOV","executionInfo":{"status":"ok","timestamp":1614548944795,"user_tz":-60,"elapsed":2617,"user":{"displayName":"tom vesoul","photoUrl":"","userId":"10135283741654588830"}}},"source":["for i in range(n_predictions):\n","  list_notes_input = list_notes[-16:]\n","  list_times_input = list_times[-16:]\n","\n","  notes_input = torch.reshape(torch.tensor(list_notes_input),(1,-1)).to(device)\n","  times_input = torch.reshape(torch.tensor(list_times_input),(1,-1)).to(device)\n","\n","  times_input = (times_input * 2) // 60 - (times_input // 60)\n","  times_input = torch.min(times_input, torch.tensor([17]).to(device))\n","\n","  inputs = (notes_input, times_input)\n","\n","  note, time = model(inputs)\n","\n","  # Sample note\n","  array_proba_note = torch.softmax(note / temp_note, 1).detach().cpu().numpy()[0]\n","  note_sampled = np.random.choice(range(num_classes_note), p=array_proba_note)\n","\n","  # Sample time\n","  array_proba_time = torch.softmax(time / temp_time, 1).detach().cpu().numpy()[0]\n","  time_sampled = np.random.choice(range(num_classes_time), p=array_proba_time)\n","\n","  final_time = time_sampled * 60\n","\n","  data.append([note_sampled, velocity, int(final_time)])\n","\n","  list_notes.append(note_sampled)\n","  list_times.append(final_time)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Tbti3brbwPx","executionInfo":{"status":"ok","timestamp":1614548944795,"user_tz":-60,"elapsed":2073,"user":{"displayName":"tom vesoul","photoUrl":"","userId":"10135283741654588830"}}},"source":["track = data_to_track(data)\n","save_track(track, 'file.mid')"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"dTKxjXwupWKd"},"source":[""],"execution_count":null,"outputs":[]}]}